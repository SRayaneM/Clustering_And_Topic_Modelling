{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLjSifPyrA-U"
      },
      "source": [
        "# LDA introduction.\n",
        "\n",
        "Natural language processing (NLP) employs the probabilistic topic modeling method known as Latent Dirichlet Allocation (LDA).\n",
        "\n",
        "By identifying the topics that most accurately represent each theme, LDA aims to reveal the hidden thematic structure of a group of documents.\n",
        "\n",
        "LDA can be used to find the topics that are most pertinent to computer science, mathematics, and physics in the case of abstracts for STEM subjects.\n",
        "\n",
        "We begin by preprocessing the text data for this purpose in order to get rid of stop words, punctuation, and other extraneous details.\n",
        "\n",
        "In order to represent the frequency of each term in each document, we tokenize the text to separate it into individual words or phrases.\n",
        "\n",
        "The topics that best explain the variation in the data can be found using LDA once we have the document-term matrix.\n",
        "\n",
        "Until the model converges on a stable solution, this entails repeatedly assigning each word in each document to a topic and adjusting the topic probabilities.\n",
        "\n",
        "The LDA model produces a list of topics, each of which is represented by a distribution over the vocabulary words.\n",
        "\n",
        "The topics can then be understood by looking at the most frequently occurring words in each topic and using domain knowledge to assign them to pertinent STEM subject areas.\n",
        "\n",
        "We previously conduct a similar procedure using TF-IDF, and this model will work in tandom with the website that we have created for the users to input their abstracts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxOdNoOsrA-V"
      },
      "source": [
        "We first begin by importing the libraries that will be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOpKdqP1rQ9E",
        "outputId": "3d53ab4b-2d76-48f9-fc9b-82cb6d998213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyLDAvis in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (3.4.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (1.2.1)\n",
            "Requirement already satisfied: pandas>=1.3.4 in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (1.3.4)\n",
            "Requirement already satisfied: funcy in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (67.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (1.2.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: numexpr in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (2.8.4)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (1.22.4)\n",
            "Requirement already satisfied: gensim in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (4.3.1)\n",
            "Requirement already satisfied: scipy in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyLDAvis) (1.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas>=1.3.4->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas>=1.3.4->pyLDAvis) (2021.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from gensim->pyLDAvis) (6.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\rayni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.7.3->pandas>=1.3.4->pyLDAvis) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pyLDAvis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Zycx5gHQrA-V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import spacy\n",
        "import pickle\n",
        "\n",
        "# libraries for visualization\n",
        "import pyLDAvis\n",
        "import pyLDAvis.lda_model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can use the following command line to import the dataset file in case youre using Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "eUJMHzdz_mo9",
        "outputId": "ea5532fd-97e1-4e44-9b70-bce521763134"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Rayni\\Desktop\\Coding\\FYP\\Main\\LDA.ipynb Cell 6\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Rayni/Desktop/Coding/FYP/Main/LDA.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m files\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rayni/Desktop/Coding/FYP/Main/LDA.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m uploaded \u001b[39m=\u001b[39m files\u001b[39m.\u001b[39mupload()\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHXdBwZcrA-W"
      },
      "source": [
        "We will then import our data set as we did before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "AaKP2sZXrA-W",
        "outputId": "1a571af2-978a-4f21-efba-30e54290981e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>Predictive models allow subject-specific inf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Rotation Invariance Neural Network</td>\n",
              "      <td>Rotation invariance and translation invarian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "      <td>We introduce and develop the notion of spher...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                              TITLE  \\\n",
              "0   1        Reconstructing Subject-Specific Effect Maps   \n",
              "1   2                 Rotation Invariance Neural Network   \n",
              "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
              "3   4  A finite element approximation for the stochas...   \n",
              "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
              "\n",
              "                                            ABSTRACT  \n",
              "0    Predictive models allow subject-specific inf...  \n",
              "1    Rotation invariance and translation invarian...  \n",
              "2    We introduce and develop the notion of spher...  \n",
              "3    The stochastic Landau--Lifshitz--Gilbert (LL...  \n",
              "4    Fourier-transform infra-red (FTIR) spectra o...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv('abstracts.csv')\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbf4wHp7rA-X"
      },
      "source": [
        "## Data cleaning and preprocessing.\n",
        "And afterwords, we will have our cleaning function. this function performs a series of common text preprocessing steps to remove noise and irrelevant information from the input text, which can improve the accuracy of natural language processing tasks. These steps include removing punctuation, removing words that are entirely composed of digits, and removing short words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDdSHy2orA-X",
        "outputId": "663a9bfa-148e-4b0d-d0d3-54375a527e11"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    #The first line of the function creates a dictionary called clean_dict that maps each punctuation character in the string.punctuation string to an empty string.\n",
        "    #This will be used to remove all punctuation characters from the text.\n",
        "    clean_dict = {special_char: '' for special_char in string.punctuation}\n",
        "    clean_dict[' '] = ' '\n",
        "    #A translation table is created using the str.maketrans() method, which takes the clean_dict dictionary as input\n",
        "    #and returns a translation table that can be used with the translate() method to remove punctuation from the text.\n",
        "    table = str.maketrans(clean_dict)\n",
        "    text_1 = text.translate(\n",
        "        table\n",
        "    )  #he translate() method is called on the input text using the translation table to remove all punctuation characters.\n",
        "    text_Array = text_1.split()\n",
        "\n",
        "    \"\"\"\n",
        "    A list comprehension is used to remove any words that are entirely composed of digits (isdigit()) or that have a length less than or equal to 3 characters.\n",
        "    The remaining words are joined back together into a string with spaces between them using the join() method.\n",
        "    The resulting cleaned text is converted to lowercase using the lower() method.\n",
        "    \"\"\"\n",
        "    text_2 = ' '.join([\n",
        "        word for word in text_Array\n",
        "        if (not word.isdigit() and (not word.isdigit() and len(word) > 3))\n",
        "    ])\n",
        "\n",
        "    return text_2.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB66_J-ZrA-X"
      },
      "source": [
        "We will then be using a Natural Language Toolkit (NLTK) library to remove stopwords from text data.\n",
        "\n",
        "Stopwords are words that occur frequently in a language but do not carry much meaning, such as \"a\", \"an\", \"the\", \"in\", \"of\", etc.\n",
        "\n",
        "The first two lines of the code import the stopwords module from NLTK and create a variable stop_words that contains a list of English stopwords.\n",
        "\n",
        "Next, a function remove_stopwords is defined that takes a single argument text, which is a string containing text data.\n",
        "\n",
        "The function splits the input text into an array of words using the split() method and then uses a list comprehension to remove any words that appear in the stop_words list.\n",
        "\n",
        "The filtered words are then joined back together into a string using the join() method and returned.\n",
        "\n",
        "Finally, the apply() method is used to apply the remove_stopwords function to every row in the 'ABSTRACT' column of the train_df DataFrame.\n",
        "\n",
        "This removes the stopwords from the text data in each row and updates the 'ABSTRACT' column in-place with the cleaned text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GOktzV4ssoN",
        "outputId": "979ded3e-8ac9-49e5-e60e-a3cff627ee20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Rayni\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Rayni\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Rayni\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3KsKu5UrA-Y",
        "outputId": "ebb11587-9324-4d6a-a0e5-789b3ad16ef2"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "\n",
        "#We then create a function to remove the stopwords in our text.\n",
        "def remove_stopwords(text):\n",
        "    text_Array = text.split(' ')\n",
        "    remove_words = \" \".join([i for i in text_Array if i not in stop_words])\n",
        "    return remove_words\n",
        "\n",
        "\n",
        "#And here we will apply the remove_stopwords function. This will remove the stopwords from our dataset's text\n",
        "train_df['ABSTRACT'] = train_df['ABSTRACT'].apply(remove_stopwords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHo4e519rA-Y",
        "outputId": "3076b65b-dd4c-4b9d-f992-3be9d2e6e8bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rayni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\n",
            "C:\\Users\\Rayni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:558: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(20972, 27)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "tf_vectorizer = CountVectorizer(analyzer=clean_text,\n",
        "                                strip_accents='unicode',\n",
        "                                stop_words='english',\n",
        "                                lowercase=True,\n",
        "                                token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
        "                                max_df=0.5,\n",
        "                                min_df=10)\n",
        "dtm_tf = tf_vectorizer.fit_transform(train_df['ABSTRACT'])\n",
        "dtm_tf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE57xgx4rA-Y",
        "outputId": "25bf8b9a-87c4-4d5f-9452-c68db9a56080"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rayni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:2070: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'numpy.int64'> 'dtype' will be converted to np.float64.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(20972, 27)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(**tf_vectorizer.get_params())\n",
        "dtm_tfidf = tfidf_vectorizer.fit_transform(train_df['ABSTRACT'])\n",
        "dtm_tfidf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "No4DTaNUrA-Z",
        "outputId": "d46ed5f7-cf7a-4fac-ad9a-79a4f5764b86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=20, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=20, random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LatentDirichletAllocation(n_components=20, random_state=0)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda_tfidf = LatentDirichletAllocation(n_components=20, random_state=0)\n",
        "lda_tfidf.fit(dtm_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ed7c0ctKrA-Z"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rayni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  default_term_info = default_term_info.sort_values(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "10     0.285814 -0.160587       1        1  20.853575\n",
              "4     -0.124704  0.118689       2        1   7.237380\n",
              "14    -0.167533 -0.049187       3        1   5.990865\n",
              "15    -0.207415  0.016300       4        1   5.926171\n",
              "13    -0.200304  0.036943       5        1   5.795898\n",
              "19    -0.201335  0.013156       6        1   5.748620\n",
              "2     -0.199290  0.033195       7        1   5.282359\n",
              "11    -0.010216  0.228120       8        1   5.231331\n",
              "6     -0.154773  0.055658       9        1   4.982194\n",
              "7     -0.201975 -0.137921      10        1   4.452306\n",
              "3     -0.190784 -0.049468      11        1   4.323611\n",
              "16     0.194800 -0.006614      12        1   3.532901\n",
              "5     -0.150529 -0.028978      13        1   3.309932\n",
              "12     0.266893  0.270302      14        1   3.013260\n",
              "9      0.266621 -0.052828      15        1   2.555161\n",
              "8      0.244879 -0.029036      16        1   2.518946\n",
              "17     0.273520 -0.028095      17        1   2.417456\n",
              "0     -0.046641 -0.196066      18        1   2.341205\n",
              "1      0.122726  0.033551      19        1   2.252454\n",
              "18     0.200248 -0.067133      20        1   2.234378, topic_info=   Term         Freq        Total Category  logprob  loglift\n",
              "0     0  1468.000000  1468.000000  Default  27.0000  27.0000\n",
              "10    j  3627.000000  3627.000000  Default  26.0000  26.0000\n",
              "1     1  1835.000000  1835.000000  Default  25.0000  25.0000\n",
              "3     3   835.000000   835.000000  Default  24.0000  24.0000\n",
              "21    ö   402.000000   402.000000  Default  23.0000  23.0000\n",
              "..  ...          ...          ...      ...      ...      ...\n",
              "5     5     0.611642   465.527584  Topic20  -6.2337  -2.8336\n",
              "4     4     0.611642   519.182656  Topic20  -6.2337  -2.9427\n",
              "3     3     0.611642   835.663905  Topic20  -6.2337  -3.4186\n",
              "2     2     0.611643  1603.485116  Topic20  -6.2337  -4.0703\n",
              "1     1     0.611642  1835.686737  Topic20  -6.2337  -4.2056\n",
              "\n",
              "[567 rows x 6 columns], token_table=      Topic      Freq Term\n",
              "term                      \n",
              "0         2  0.002724    0\n",
              "0         3  0.015665    0\n",
              "0         4  0.099437    0\n",
              "0         5  0.074237    0\n",
              "0         6  0.088540    0\n",
              "...     ...       ...  ...\n",
              "25       12  0.916355    ő\n",
              "25       19  0.038181    ő\n",
              "25       20  0.038181    ő\n",
              "26       19  0.979224    š\n",
              "26       20  0.007772    š\n",
              "\n",
              "[169 rows x 3 columns], R=27, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[11, 5, 15, 16, 14, 20, 3, 12, 7, 8, 4, 17, 6, 13, 10, 9, 18, 1, 2, 19])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pyLDAvis.lda_model.prepare(lda_tfidf, dtm_tfidf, tfidf_vectorizer)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WOpDJIT2rA-Y"
      },
      "source": [
        "We will use the SpaCy library to perform lemmatization on a list of input texts. Lemmatization is the process of reducing words to their base or dictionary form, which can be useful for standardizing text data and reducing noise in natural language processing tasks. However before beginning to use the Spacy library, you must first install the required tools to begin using the Spacy library. Run the following commands in the terminal to install the required tools.\n",
        "````\n",
        "pip install -U pip setuptools wheel\n",
        "pip install -U spacy\n",
        "python -m spacy download en_core_web_sm\n",
        "````\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eboi-l2nrA-Z",
        "outputId": "c4407019-47e3-414e-ca57-5f09065f9ee7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "The first line of the code loads the 'en_core_web_md' SpaCy model, \n",
        "which is a medium-sized English language model that includes word vectors and supports part-of-speech tagging, \n",
        "named entity recognition, and dependency parsing. The 'parser' and 'ner' components are disabled using the disable parameter, \n",
        "which speeds up the processing time since these components are not needed for lemmatization.\n",
        "'''\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
        "\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['VERB', 'ADV', 'ADJ']):\n",
        "    output = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(sent)\n",
        "        output.append(\n",
        "            [token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-uyIu1ZrA-Z",
        "outputId": "98232712-b9a2-4640-c15a-e9616896a1d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Rotation invariance translation invariance great values image\n",
            "recognition tasks. In paper, bring new architecture convolutional\n",
            "neural network (CNN) named cyclic convolutional layer achieve rotation\n",
            "invariance 2-D symbol recognition. We also get position and\n",
            "orientation 2-D symbol network achieve detection purpose for\n",
            "multiple non-overlap target. Last least, architecture achieve\n",
            "one-shot learning cases using invariance.\n",
            "\n",
            "['great', 'bring', 'new', 'convolutional', 'neural', 'name', 'cyclic', 'convolutional', 'achieve', 'd', 'also', 'get', 'd', 'achieve', 'multiple', 'non', '-', 'overlap', 'last', 'least', 'achieve', 'use']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "text_list=train_df['ABSTRACT'].tolist()\n",
        "print(text_list[1])\n",
        "tokenized_reviews = lemmatization(text_list)\n",
        "print(tokenized_reviews[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydDDSn1sugpj",
        "outputId": "dc10c176-076e-4ba0-810b-4a0606d539b4"
      },
      "outputs": [],
      "source": [
        "dictionary = corpora.Dictionary(tokenized_reviews)\n",
        "doc_term_matrix = [dictionary.doc2bow(rev) for rev in tokenized_reviews]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV9hA_uHuk4a",
        "outputId": "e12208f8-3642-474a-b638-dab39d73e3f8"
      },
      "outputs": [],
      "source": [
        "LDA = gensim.models.ldamodel.LdaModel\n",
        "\n",
        "# Build LDA model\n",
        "lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=4, random_state=100,\n",
        "                chunksize=1000, passes=50,iterations=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aeSILVA2CLk",
        "outputId": "b6da8618-6ae6-4e94-f6e2-2ce1ddcd48b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.019*\"give\" + 0.018*\"show\" + 0.017*\"prove\" + 0.013*\"also\" + 0.012*\"-\" + 0.009*\"non\" + 0.009*\"obtain\" + 0.008*\"study\" + 0.008*\"set\" + 0.008*\"use\"'),\n",
              " (1,\n",
              "  '0.024*\"use\" + 0.015*\"propose\" + 0.015*\"base\" + 0.014*\"learn\" + 0.009*\"show\" + 0.008*\"neural\" + 0.008*\"different\" + 0.008*\"deep\" + 0.008*\"present\" + 0.007*\"new\"'),\n",
              " (2,\n",
              "  '0.020*\"propose\" + 0.019*\"use\" + 0.015*\"show\" + 0.015*\"-\" + 0.013*\"base\" + 0.010*\"optimal\" + 0.009*\"random\" + 0.009*\"provide\" + 0.008*\"consider\" + 0.008*\"well\"'),\n",
              " (3,\n",
              "  '0.013*\"use\" + 0.011*\"find\" + 0.011*\"high\" + 0.011*\"-\" + 0.010*\"show\" + 0.008*\"low\" + 0.008*\"magnetic\" + 0.008*\"large\" + 0.007*\"present\" + 0.007*\"observe\"')]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda_model.print_topics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "id": "dNc9fPUd2GLD",
        "outputId": "298c5015-0931-49ea-fbcd-a89b1cce7129"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rayni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  default_term_info = default_term_info.sort_values(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1072412247271202404409269111\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1072412247271202404409269111_data = {\"mdsDat\": {\"x\": [-0.13083144054624163, -0.008953604155956595, -0.07629934320524971, 0.21608438790744772], \"y\": [-0.06814963209784645, -0.10612452701387724, 0.16254063235687366, 0.011733526754850003], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [36.141004621124104, 23.92824552873006, 23.21963369867676, 16.711116151469074]}, \"tinfo\": {\"Term\": [\"propose\", \"learn\", \"prove\", \"give\", \"optimal\", \"neural\", \"deep\", \"random\", \"magnetic\", \"finite\", \"define\", \"non\", \"show\", \"train\", \"optical\", \"set\", \"bound\", \"social\", \"study\", \"linear\", \"consider\", \"invariant\", \"human\", \"base\", \"solve\", \"numerical\", \"positive\", \"observe\", \"approximate\", \"find\", \"learn\", \"neural\", \"deep\", \"train\", \"social\", \"human\", \"adversarial\", \"visual\", \"convolutional\", \"semantic\", \"generative\", \"dataset\", \"automatic\", \"scientific\", \"automate\", \"supervised\", \"mobile\", \"public\", \"autonomous\", \"latent\", \"supervise\", \"recurrent\", \"clinical\", \"medical\", \"digital\", \"smart\", \"unsupervised\", \"deploy\", \"meta\", \"robotic\", \"collect\", \"temporal\", \"label\", \"automatically\", \"share\", \"evaluate\", \"help\", \"challenge\", \"base\", \"use\", \"propose\", \"make\", \"different\", \"improve\", \"able\", \"enable\", \"real\", \"however\", \"available\", \"generate\", \"predict\", \"achieve\", \"new\", \"present\", \"perform\", \"provide\", \"well\", \"demonstrate\", \"exist\", \"show\", \"many\", \"also\", \"large\", \"develop\", \"-\", \"high\", \"compare\", \"optimal\", \"bayesian\", \"sparse\", \"variational\", \"posterior\", \"stochastic\", \"guarantee\", \"conditional\", \"parametric\", \"gradient\", \"gaussian\", \"causal\", \"regularize\", \"randomize\", \"marginal\", \"nonparametric\", \"greedy\", \"tractable\", \"unbiased\", \"surrogate\", \"cost\", \"intractable\", \"enforce\", \"provably\", \"corrupt\", \"constraint\", \"penalize\", \"class\", \"smoothness\", \"proximal\", \"random\", \"approximate\", \"sample\", \"unknown\", \"iterative\", \"minimize\", \"solve\", \"convex\", \"estimate\", \"numerical\", \"theoretical\", \"statistical\", \"empirical\", \"distribute\", \"linear\", \"efficient\", \"propose\", \"computational\", \"adaptive\", \"derive\", \"-\", \"consider\", \"use\", \"show\", \"base\", \"non\", \"provide\", \"well\", \"low\", \"large\", \"dimensional\", \"also\", \"new\", \"high\", \"first\", \"demonstrate\", \"present\", \"allow\", \"develop\", \"apply\", \"magnetic\", \"optical\", \"thermal\", \"electronic\", \"stellar\", \"molecular\", \"dark\", \"scatter\", \"solar\", \"gravitational\", \"superconducte\", \"atomic\", \"orbital\", \"electric\", \"thin\", \"mass\", \"mechanical\", \"hot\", \"angular\", \"solid\", \"cosmological\", \"cosmic\", \"radial\", \"bulk\", \"continuum\", \"electromagnetic\", \"atmospheric\", \"charge\", \"cool\", \"dope\", \"couple\", \"light\", \"observe\", \"find\", \"induce\", \"high\", \"report\", \"low\", \"here\", \"measure\", \"suggest\", \"large\", \"long\", \"-\", \"investigate\", \"strong\", \"use\", \"show\", \"present\", \"critical\", \"single\", \"due\", \"small\", \"study\", \"also\", \"different\", \"well\", \"demonstrate\", \"non\", \"first\", \"base\", \"dimensional\", \"provide\", \"obtain\", \"invariant\", \"let\", \"manifold\", \"infinite\", \"theorem\", \"algebraic\", \"algebra\", \"maximal\", \"admit\", \"rational\", \"euclidean\", \"prime\", \"hyperbolic\", \"singular\", \"elliptic\", \"riemannian\", \"integrable\", \"denote\", \"finitely\", \"proof\", \"conjecture\", \"vertice\", \"irreducible\", \"\\\\mathcal\", \"f$\", \"projective\", \"say\", \"commutative\", \"boolean\", \"parabolic\", \"symmetric\", \"fractional\", \"prove\", \"integral\", \"regular\", \"boundary\", \"geometric\", \"positive\", \"metric\", \"polynomial\", \"finite\", \"give\", \"define\", \"bound\", \"compact\", \"generalize\", \"certain\", \"complete\", \"construct\", \"explicit\", \"show\", \"set\", \"study\", \"also\", \"obtain\", \"non\", \"general\", \"classical\", \"-\", \"consider\", \"introduce\", \"particular\", \"know\", \"new\", \"use\", \"first\", \"dimensional\", \"provide\", \"associate\", \"present\"], \"Freq\": [8755.0, 4342.0, 2904.0, 4644.0, 2101.0, 2549.0, 2443.0, 1911.0, 1656.0, 1432.0, 1864.0, 3773.0, 10392.0, 1388.0, 949.0, 3077.0, 1204.0, 1209.0, 3189.0, 1855.0, 3606.0, 667.0, 1176.0, 8270.0, 1684.0, 1358.0, 969.0, 1984.0, 909.0, 4190.0, 4342.186367117881, 2548.8389370529635, 2443.0754378322144, 1387.4300871569799, 1208.4930173565224, 1175.7576106164106, 717.8943114621196, 665.6936091046305, 594.143752680849, 511.09758336908806, 500.77451981687204, 413.7065507043863, 361.47116177627106, 356.5167573667414, 341.3375739268718, 334.1318020430887, 332.3149910435331, 313.0321276551177, 292.16381517336566, 279.57554849232065, 240.81043593796343, 248.6680071031796, 237.2505981914863, 227.94322403675577, 227.12468828814556, 208.79593589093562, 208.2687637925233, 190.48027510541758, 194.62197210225943, 184.02703173727593, 452.3010825700006, 768.3773376766535, 425.70424220414316, 379.3665623396426, 457.0354983002479, 1145.3915907241533, 478.19171994738065, 645.2477358277557, 4667.586223600252, 7345.002573635381, 4680.894245479441, 1692.6849471324015, 2541.5776453978106, 1518.233676447193, 783.0387381306908, 906.6703209117953, 1742.6878885338776, 1756.9322706669045, 900.3266112853192, 1367.438717790209, 1015.2134226236155, 1370.8773296925624, 2282.577167914528, 2369.4602600857197, 1246.2026696497292, 2255.4018873525097, 2196.0255645633342, 1616.8676858950455, 1377.1080156619423, 2874.349053604577, 1343.8378192415134, 2028.6078375496377, 1771.287763203898, 1337.3919985869022, 2272.28981842073, 1783.6261200525516, 1226.654891564101, 2101.1153921454575, 780.9099166083862, 477.85816770368325, 477.44873334950523, 444.50275613619704, 452.94614920220596, 446.5410139014386, 423.3880102093111, 405.5535245294078, 376.50643955508303, 349.30521057145137, 229.5421667458563, 224.36296525875318, 178.81812012523548, 172.26660746855708, 159.22973346027544, 139.858144795849, 141.9888032670094, 135.24315295047208, 127.72421264393377, 129.7450998271157, 116.11950266157469, 121.79671556950964, 108.31429375521908, 109.89868788549812, 116.14393407442427, 105.38381439829881, 107.68028510347473, 101.01285518650238, 99.20270213422214, 1856.778556393269, 879.1013951755232, 851.59267991284, 575.8713661578516, 269.6352060247962, 382.5224785092966, 1236.8093697135544, 681.1549214505152, 1193.906542022592, 998.2726428577012, 953.0266514925017, 926.5121762703526, 647.5509967887148, 723.6868326748647, 1227.7788251702293, 1102.654147694563, 4074.283088142211, 865.2989488294993, 466.3636043358562, 1088.2508035361968, 3005.3312944981344, 1582.9031455447928, 3819.071165498942, 3032.328345836598, 2591.939684802065, 1541.965996846766, 1733.4057156066144, 1572.7597577699905, 1303.848697414581, 1343.0493039806556, 989.7258004103512, 1452.1901371806703, 1303.714893498216, 1324.848874910975, 1093.4516097580427, 1046.1414161795828, 1153.2277118250927, 973.990234649918, 966.1116611312849, 953.1507907501109, 1655.511722297489, 948.4541355112326, 620.8433239673093, 628.5130743887461, 563.5227429942782, 570.2479561030292, 524.249758372281, 513.8741432388629, 421.5952561388059, 419.3413780485213, 409.98733098563645, 416.64684942324436, 365.7007002414609, 346.1551697828142, 333.2920348042213, 329.6155461221979, 315.9866334471655, 283.290809909971, 279.3962267566302, 273.09368123408325, 256.1280893194473, 253.1816855950026, 255.34924553110335, 235.35723715152793, 232.21818824278523, 219.37975136474338, 213.33791307317415, 211.88555094464255, 199.71614805120444, 198.92168868960886, 698.5422735601484, 478.72822260055443, 1271.2668231597215, 2244.906829635438, 680.7957891668002, 2214.7652221965195, 605.1527686482166, 1657.869992543651, 846.4880842944074, 643.4190268232373, 729.7944532844897, 1572.40300091815, 752.670812833577, 2147.973363545085, 883.6210069576914, 779.3344724503859, 2522.5378820075257, 1925.9104424049954, 1360.8406650239442, 653.7087335405454, 816.9188354179353, 741.5501573028915, 882.8407746125423, 967.4200914646907, 1260.82897336556, 1079.018811634488, 1018.528815608811, 739.6666369047407, 744.8889307593159, 740.0864363244291, 796.6210486192798, 688.9780308654773, 715.7489508046791, 689.0054377899597, 667.179902038209, 598.4182887937114, 469.87301159781975, 462.50603290737763, 418.8511771417957, 364.19944095868163, 345.89652527456803, 320.536787056068, 288.740178197195, 272.0947434330384, 244.9512632817607, 235.48206412094726, 233.03269549154248, 234.12258343755553, 216.1584116177333, 210.59960137753555, 210.62260260525065, 192.6726345350217, 178.48929771218909, 180.26204689297475, 179.45487417963935, 176.44215568026374, 167.2818839774443, 149.98987552793741, 141.10792851005516, 132.89828411493525, 139.22500606973674, 127.19470866910756, 129.82567887203217, 129.00167299525145, 548.0954033257478, 234.8921088422803, 2431.9736724403383, 408.00849013968707, 432.68517053172457, 666.1820681509788, 498.5952540799012, 737.8662789876862, 585.5747571026425, 594.8655493048965, 1012.4295095919695, 2652.313638449585, 1140.453425626319, 802.2921935731695, 542.6700624603328, 751.635692007492, 688.3211102448588, 552.9296585102792, 736.3805700567555, 478.35918677870677, 2560.2471288597, 1168.7070590503074, 1183.6336107567035, 1793.8536918768489, 1202.2234520121863, 1226.3213992345204, 885.2125369139839, 669.7878218654961, 1707.4435183879787, 1043.1987958101315, 871.3329670172861, 754.8765715456057, 753.4098009474659, 918.1000330599601, 1151.4653125428447, 765.0804666167547, 695.8425117076958, 751.1050910365258, 626.4606516816501, 669.750403913857], \"Total\": [8755.0, 4342.0, 2904.0, 4644.0, 2101.0, 2549.0, 2443.0, 1911.0, 1656.0, 1432.0, 1864.0, 3773.0, 10392.0, 1388.0, 949.0, 3077.0, 1204.0, 1209.0, 3189.0, 1855.0, 3606.0, 667.0, 1176.0, 8270.0, 1684.0, 1358.0, 969.0, 1984.0, 909.0, 4190.0, 4342.9516771103445, 2549.594326126974, 2443.8408870275803, 1388.1822773612544, 1209.2470923994986, 1176.507232677752, 718.6545610674469, 666.4468003496768, 594.8932018259288, 511.8477742404673, 501.53474440911106, 414.4704397109729, 362.2310576950628, 357.29444330780416, 342.09695157897016, 334.8895022132823, 333.078800894706, 313.7857617577237, 292.94588523184865, 280.37965145045905, 241.56301500811222, 249.44764734160586, 238.00682097259056, 228.70454832565017, 227.8923016703016, 209.55189555104624, 209.02410045141144, 191.24599850926694, 195.40728889378417, 184.78049950939908, 469.7584560457585, 825.5282867423871, 452.3234478751557, 400.9351370171722, 491.22391653975234, 1412.556251226993, 543.0531156469705, 779.0829888321714, 8270.311666781769, 14838.076933684693, 8755.69754234948, 2564.660410645728, 4368.283857006494, 2304.9387939643593, 1003.5544496504058, 1214.6891228597985, 2854.3693936045706, 2925.7730114063465, 1224.1694952381747, 2180.942663160063, 1522.7983473888664, 2346.1394689410445, 5096.857096037853, 5553.2790408486135, 2132.2977143435637, 5455.661644800329, 5358.667779852209, 3402.9318494912936, 2601.5779832914905, 10392.83497070587, 2693.0508771948334, 6535.480639972717, 4965.178841750573, 2777.802279514904, 9133.03799485193, 5412.9353722561245, 2658.8924692467367, 2101.878565077744, 781.6674802409045, 478.62200834504097, 478.22218570705525, 445.2493352189021, 453.7097888196249, 447.308603453919, 424.14719401394, 406.3201942573043, 377.28476777441904, 350.066390183857, 230.30851359626718, 225.12763903726722, 179.57718568445972, 173.026208816865, 159.98210108970724, 140.61122989382935, 142.7676952939897, 136.0295225119376, 128.47739925963367, 130.54593185402612, 116.8845607668259, 122.60446859504506, 109.06445892582056, 110.66527139948629, 116.96220971632462, 106.14150004004038, 108.47642988621381, 101.77367439870552, 99.95928146309419, 1911.710406081295, 909.3237179084944, 905.6418473590779, 612.1433064259566, 282.76801300444384, 440.1080595155874, 1684.2535850588918, 867.4223954549939, 1648.2817985923205, 1358.5905745661114, 1334.5015321372537, 1292.5971269267193, 851.7383566496785, 973.0622600368573, 1855.767162963082, 1659.9648983599318, 8755.69754234948, 1341.2093592212375, 593.2929946654792, 2094.1656381784533, 9133.03799485193, 3606.355798610204, 14838.076933684693, 10392.83497070587, 8270.311666781769, 3773.8876600737394, 5455.661644800329, 5358.667779852209, 3710.8684197886505, 4965.178841750573, 2493.6566783205635, 6535.480639972717, 5096.857096037853, 5412.9353722561245, 3691.265328564834, 3402.9318494912936, 5553.2790408486135, 2657.56518853789, 2777.802279514904, 2850.435295922286, 1656.258066591203, 949.2062126034778, 621.588105042075, 629.2791299209266, 564.2635988195761, 571.0084610613092, 524.9967016900785, 514.6299887865638, 422.3456933675838, 420.09386288904545, 410.73107032229876, 417.41018806449085, 366.4501591355312, 346.91457742711606, 334.0427348856887, 330.3665778696932, 316.74590123859394, 284.0558081226539, 280.1566656409039, 273.8606730662518, 256.8783830064808, 253.9265984958449, 256.11548283448303, 236.10996085487344, 233.0027043165663, 220.1367077040686, 214.09445232236703, 212.6428652547139, 200.4576799621961, 199.6616279110239, 747.9052129868222, 575.8227489384346, 1984.0903690793905, 4190.686078809319, 1008.7850115870726, 5412.9353722561245, 890.753627219021, 3710.8684197886505, 1517.3391933926748, 1037.6502645383507, 1262.5694406528132, 4965.178841750573, 1469.1867210907214, 9133.03799485193, 1939.1839745807056, 1574.8330499894898, 14838.076933684693, 10392.83497070587, 5553.2790408486135, 1189.1829645564253, 2001.132371107174, 1632.7725587540463, 2545.81752757146, 3189.1793052320677, 6535.480639972717, 4368.283857006494, 5358.667779852209, 3402.9318494912936, 3773.8876600737394, 3691.265328564834, 8270.311666781769, 2493.6566783205635, 5455.661644800329, 3345.488928736714, 667.9573433486244, 599.1690442072063, 470.643167351838, 463.2747609082291, 419.60758022114413, 364.9571919946556, 346.64222723010306, 321.3144233143679, 289.4984650590202, 272.8530441556011, 245.72432639525164, 236.24289049060044, 233.79514984862053, 234.90536241951452, 216.90574460388547, 211.35039460382418, 211.37572967180432, 193.45243583256064, 179.2332414510307, 181.0242185876327, 180.21437375381367, 177.211312362997, 168.02502471819977, 150.73959991958392, 141.86278330053082, 133.6421033696983, 140.00438378931764, 127.93880763298318, 130.5944005658752, 129.76719685345716, 579.7205363372227, 242.5689414650723, 2904.680933126237, 440.98378977370214, 473.9230994448514, 776.0556974279868, 589.0960788436744, 969.9708551523994, 738.3449908369157, 753.5233390591253, 1432.7785166670333, 4644.272082297227, 1864.577340911912, 1204.8881106045492, 726.0641378717946, 1186.5347219751782, 1133.5220754945433, 848.1741911050324, 1363.5037931591473, 706.8083076700365, 10392.83497070587, 3077.474252887084, 3189.1793052320677, 6535.480639972717, 3345.488928736714, 3773.8876600737394, 2060.983654672072, 1230.215480293744, 9133.03799485193, 3606.355798610204, 2803.8984228177014, 2043.8617714650409, 2241.195582464347, 5096.857096037853, 14838.076933684693, 3691.265328564834, 2493.6566783205635, 5455.661644800329, 1365.4546992670826, 5553.2790408486135], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.2498, -4.7825, -4.8249, -5.3907, -5.5288, -5.5563, -6.0496, -6.1251, -6.2388, -6.3894, -6.4098, -6.6008, -6.7357, -6.7495, -6.7931, -6.8144, -6.8198, -6.8796, -6.9486, -6.9927, -7.1419, -7.1098, -7.1568, -7.1968, -7.2004, -7.2846, -7.2871, -7.3764, -7.3549, -7.4108, -6.5116, -5.9816, -6.5722, -6.6874, -6.5012, -5.5824, -6.4559, -6.1563, -4.1775, -3.7241, -4.1747, -5.1919, -4.7854, -5.3006, -5.9627, -5.8161, -5.1627, -5.1546, -5.8232, -5.4052, -5.7031, -5.4027, -4.8929, -4.8555, -5.4981, -4.9048, -4.9315, -5.2377, -5.3982, -4.6623, -5.4226, -5.0108, -5.1465, -5.4274, -4.8974, -5.1395, -5.5139, -4.5633, -5.5531, -6.0442, -6.0451, -6.1166, -6.0978, -6.112, -6.1653, -6.2083, -6.2826, -6.3576, -6.7775, -6.8003, -7.0272, -7.0645, -7.1432, -7.2729, -7.2578, -7.3065, -7.3637, -7.348, -7.4589, -7.4112, -7.5285, -7.514, -7.4587, -7.5559, -7.5344, -7.5983, -7.6164, -4.687, -5.4347, -5.4664, -5.8577, -6.6165, -6.2668, -5.0933, -5.6898, -5.1286, -5.3075, -5.3539, -5.3821, -5.7404, -5.6292, -5.1006, -5.2081, -3.9011, -5.4505, -6.0686, -5.2212, -4.2054, -4.8465, -3.9658, -4.1965, -4.3534, -4.8727, -4.7557, -4.853, -5.0405, -5.0109, -5.3161, -4.9327, -5.0406, -5.0245, -5.2165, -5.2607, -5.1632, -5.3322, -5.3403, -5.3538, -4.7716, -5.3287, -5.7524, -5.7401, -5.8493, -5.8374, -5.9215, -5.9415, -6.1394, -6.1448, -6.1674, -6.1513, -6.2817, -6.3366, -6.3745, -6.3856, -6.4278, -6.537, -6.5509, -6.5737, -6.6378, -6.6494, -6.6409, -6.7224, -6.7358, -6.7927, -6.8206, -6.8274, -6.8866, -6.8906, -5.6345, -6.0124, -5.0357, -4.4671, -5.6602, -4.4806, -5.778, -4.7702, -5.4424, -5.7167, -5.5907, -4.8231, -5.5599, -4.5112, -5.3995, -5.5251, -4.3505, -4.6203, -4.9676, -5.7008, -5.478, -5.5747, -5.4003, -5.3089, -5.044, -5.1997, -5.2574, -5.5773, -5.5703, -5.5767, -5.5031, -5.6483, -5.6102, -5.6482, -5.3515, -5.4603, -5.7021, -5.7179, -5.8171, -5.9569, -6.0084, -6.0846, -6.189, -6.2484, -6.3535, -6.3929, -6.4034, -6.3987, -6.4786, -6.5046, -6.5045, -6.5936, -6.67, -6.6602, -6.6646, -6.6816, -6.7349, -6.844, -6.905, -6.965, -6.9185, -7.0088, -6.9884, -6.9947, -5.5481, -6.3954, -4.0581, -5.8433, -5.7846, -5.353, -5.6428, -5.2508, -5.482, -5.4662, -4.9345, -3.9714, -4.8154, -5.1671, -5.5581, -5.2323, -5.3203, -5.5393, -5.2528, -5.6842, -4.0067, -4.7909, -4.7782, -4.3624, -4.7626, -4.7428, -5.0687, -5.3476, -4.4118, -4.9045, -5.0845, -5.228, -5.23, -5.0323, -4.8058, -5.2146, -5.3094, -5.233, -5.4145, -5.3477], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0176, 1.0174, 1.0174, 1.0172, 1.0171, 1.0171, 1.0167, 1.0166, 1.0165, 1.0163, 1.0162, 1.0159, 1.0156, 1.0156, 1.0155, 1.0155, 1.0154, 1.0153, 1.0151, 1.0149, 1.0146, 1.0146, 1.0146, 1.0144, 1.0144, 1.0141, 1.0141, 1.0137, 1.0137, 1.0137, 0.9799, 0.946, 0.9571, 0.9624, 0.9456, 0.8081, 0.8905, 0.8293, 0.4457, 0.3146, 0.3915, 0.6022, 0.4762, 0.6002, 0.7696, 0.7253, 0.5243, 0.5078, 0.7105, 0.5509, 0.6123, 0.4804, 0.2144, 0.166, 0.4806, 0.1344, 0.1257, 0.2736, 0.3816, -0.2675, 0.3226, -0.1522, -0.013, 0.2868, -0.3734, -0.0924, 0.2441, 1.4297, 1.4291, 1.4285, 1.4285, 1.4284, 1.4284, 1.4284, 1.4283, 1.4282, 1.428, 1.4279, 1.4268, 1.4267, 1.4259, 1.4257, 1.4254, 1.4247, 1.4246, 1.4243, 1.4242, 1.424, 1.4235, 1.4235, 1.4232, 1.4232, 1.4231, 1.4229, 1.4227, 1.4226, 1.4225, 1.401, 1.3963, 1.3686, 1.369, 1.3826, 1.2899, 1.1213, 1.1884, 1.1076, 1.1219, 1.0934, 1.0971, 1.156, 1.134, 1.017, 1.021, 0.6651, 0.9919, 1.1894, 0.7755, 0.3186, 0.6067, 0.0729, 0.1983, 0.2698, 0.5351, 0.2835, 0.2042, 0.3842, 0.1226, 0.506, -0.0741, 0.0667, 0.0226, 0.2135, 0.2506, -0.1417, 0.4263, 0.374, 0.3347, 1.4597, 1.4594, 1.459, 1.459, 1.4589, 1.4588, 1.4587, 1.4587, 1.4584, 1.4584, 1.4584, 1.4583, 1.4581, 1.458, 1.4579, 1.4579, 1.4578, 1.4575, 1.4575, 1.4574, 1.4572, 1.4572, 1.4572, 1.457, 1.4568, 1.4567, 1.4566, 1.4566, 1.4565, 1.4565, 1.3919, 1.2755, 1.015, 0.836, 1.0669, 0.5665, 1.0736, 0.6544, 0.8766, 0.9823, 0.912, 0.3103, 0.7913, 0.0128, 0.6742, 0.7567, -0.3118, -0.2255, 0.0539, 0.8618, 0.5642, 0.6709, 0.4011, 0.2673, -0.1853, 0.0619, -0.2002, -0.066, -0.1625, -0.1468, -0.8799, 0.1739, -0.5709, -0.1199, 1.7879, 1.7878, 1.7875, 1.7874, 1.7873, 1.787, 1.7869, 1.7867, 1.7865, 1.7863, 1.7859, 1.7859, 1.7858, 1.7858, 1.7856, 1.7855, 1.7855, 1.7851, 1.7849, 1.7849, 1.7849, 1.7847, 1.7847, 1.7841, 1.7838, 1.7835, 1.7835, 1.7833, 1.7832, 1.7832, 1.733, 1.7569, 1.6115, 1.7114, 1.6981, 1.6364, 1.6223, 1.5156, 1.5573, 1.5527, 1.4418, 1.2289, 1.2975, 1.3824, 1.498, 1.3326, 1.2903, 1.3612, 1.173, 1.3987, 0.3881, 0.8209, 0.7979, 0.4962, 0.7657, 0.665, 0.944, 1.1811, 0.1122, 0.5487, 0.6204, 0.7931, 0.6989, 0.075, -0.7671, 0.2154, 0.5127, -0.1938, 1.0099, -0.3261]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 4, 1, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 2, 4, 1, 2, 3, 4, 3, 3, 1, 1, 1, 2, 1, 1, 2, 3, 1, 2, 3, 4, 2, 4, 2, 4, 3, 4, 3, 2, 1, 2, 3, 4, 1, 2, 3, 3, 2, 1, 2, 3, 4, 1, 1, 3, 4, 1, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 2, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 3, 2, 4, 1, 3, 2, 3, 3, 2, 2, 3, 1, 2, 3, 4, 3, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 3, 3, 3, 4, 1, 2, 1, 2, 3, 2, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 4, 4, 1, 2, 3, 4, 2, 3, 4, 4, 1, 2, 3, 4, 3, 4, 2, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 1, 2, 4, 1, 2, 3, 4, 2, 3, 2, 2, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 4, 1, 2, 4, 1, 2, 3, 4, 4, 4, 3, 4, 2, 1, 2, 3, 4, 4, 1, 2, 3, 4, 4, 1, 2, 1, 2, 3, 4, 1, 4, 1, 2, 3, 4, 1, 1, 4, 1, 3, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 3, 1, 1, 1, 4, 1, 2, 1, 3, 1, 1, 2, 3, 4, 1, 2, 3, 4, 2, 2, 3, 1, 2, 3, 1, 2, 3, 4, 3, 2, 3, 4, 2, 1, 2, 3, 4, 2, 1, 2, 3, 2, 4, 1, 3, 4, 2, 1, 3, 1, 2, 3, 4, 4, 4, 4, 1, 2, 2, 2, 4, 1, 2, 3, 4, 2, 1, 3, 2, 4, 2, 4, 1, 2, 4, 1, 1, 4, 2, 1, 3, 4, 1, 1, 2, 4, 3, 1, 1, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 1, 3, 3, 1, 2, 4, 2, 1, 2, 3, 3, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 3, 1, 1, 2, 3, 4, 1, 3, 4, 2, 3, 3, 3, 2, 1, 2, 1, 2, 1, 1, 2, 3, 4, 2, 4, 1, 1, 2, 3, 4], \"Freq\": [0.2487671683048588, 0.32902523800884714, 0.23519008693610768, 0.18690385400369453, 0.9950935260543449, 0.7802267233957886, 0.08270602559623302, 0.1215678930450654, 0.014946872095704762, 0.5843642367172723, 0.3810515154086371, 0.034524801731655036, 0.2123739891300141, 0.7854466582110046, 0.9982781771954522, 0.9990891853987892, 0.9981472908386411, 0.997377248576952, 0.3488155263314563, 0.36650088742916764, 0.1783587480918126, 0.10611216658626825, 0.31045918606048695, 0.22217187686536571, 0.19294678837963236, 0.2745016164576213, 0.9958713613389928, 0.3725746736013454, 0.3343349001337873, 0.14874921055270285, 0.1441885036253794, 0.9666524502646417, 0.03299155120357139, 0.19260983183196564, 0.1098535162539728, 0.23874830865863422, 0.4584553411665798, 0.9948879930773774, 0.9990173022216039, 0.9967934482493717, 0.9966014573601274, 0.9452900606807312, 0.05237754953639935, 0.9967711264109409, 0.7351923107877278, 0.18461495804225164, 0.08005427384133036, 0.564428547324198, 0.31341019594351355, 0.09636879867553251, 0.02587568747373144, 0.9991460816040361, 0.9954484988383911, 0.3336409384920378, 0.6656219718174485, 0.1404538364465967, 0.8581858263617743, 0.9952989664186355, 0.9986604333836829, 0.1596792898109476, 0.194085324632091, 0.0388170649264182, 0.6069577424858119, 0.8278963977468448, 0.13734095280451533, 0.03337256797119064, 0.9969767842718642, 0.9956079870372434, 0.0699064524691767, 0.2812515413294784, 0.10485967870376506, 0.5446200366784697, 0.9957697810151983, 0.9621966229299155, 0.03618881103939948, 0.992662057351071, 0.05784612930079214, 0.19419771979551645, 0.7478678145316697, 0.46147033555953043, 0.31780149433398797, 0.22076861204029694, 0.17685046488454748, 0.054234142564594565, 0.11672130682380134, 0.6519887138743651, 0.35415798192446624, 0.6449403249782385, 0.997295292695247, 0.9932615044598352, 0.14973564178223955, 0.43894726100238, 0.12200681922997297, 0.2892116192201405, 0.9917733281659237, 0.19508563256996575, 0.23688969669210128, 0.027869376081423678, 0.5397858104191534, 0.9956965979450436, 0.7850846410793801, 0.21442840417146064, 0.9984985509614376, 0.9977168250062437, 0.993988435657608, 0.9963509199062498, 0.9965805491446952, 0.9958180860462463, 0.06551632365860159, 0.9346104130073981, 0.23966034537528652, 0.06643216591104434, 0.5499574241243417, 0.14463712071771678, 0.9981015086630642, 0.9988649619709888, 0.9996559158036663, 0.21238057081951217, 0.14319599093133775, 0.03325150351214584, 0.6113986129652623, 0.47517848476504937, 0.3073820006581581, 0.21745954157460515, 0.9976612554366995, 0.993484838799351, 0.039633923165788856, 0.519538655474437, 0.22061292171800542, 0.22013540457142966, 0.4813157544940471, 0.3477569325663796, 0.09935912359039417, 0.07127937127136973, 0.5819218904290681, 0.10942512337729919, 0.24700775758181134, 0.061580247256262516, 0.9960845466750671, 0.047721084074871335, 0.3970073381018708, 0.2763010666183727, 0.2791081892110122, 0.25589318405028727, 0.7440428323389878, 0.9966862540491819, 0.3190891451517107, 0.17699954500737888, 0.4544417383926475, 0.04960886901590896, 0.30603056757520053, 0.6644718819595398, 0.029518696478710287, 0.9973636811865936, 0.9948363554814461, 0.9995564290826526, 0.9958242479675237, 0.23951017164758914, 0.7607970158217537, 0.7466931109620939, 0.1243116425085735, 0.12925117797249033, 0.9950697670160654, 0.14985301676627444, 0.7243906964329219, 0.12558532174339598, 0.9970522804726849, 0.8105871883016448, 0.15433013716136118, 0.03468888404085641, 0.5292941471844075, 0.26522364673728477, 0.04228203063927728, 0.16297800900957787, 0.1174292932034231, 0.20514756041561868, 0.6762795439907981, 0.9939181843154519, 0.23480642107164934, 0.14675401316978084, 0.5357118041726145, 0.08256404643373036, 0.24288471382829405, 0.05025200975757808, 0.7063199149259586, 0.9931193486149854, 0.2961044256401257, 0.2961044256401257, 0.2004732616410732, 0.20724600696678513, 0.02885777526884222, 0.9687967411682746, 0.996953748735213, 0.14119471512562853, 0.3770044455416267, 0.05240216231466626, 0.429406607856293, 0.11377669570029164, 0.251994311217683, 0.6337783345675505, 0.6267931858507889, 0.045851732688426405, 0.14443295796854316, 0.18294841342682133, 0.9989337839201129, 0.10015344205958727, 0.052622994980461114, 0.8470604675887128, 0.1793607233252294, 0.2034764508311426, 0.046078265055941287, 0.5710259763007304, 0.9992452179394921, 0.997396146467071, 0.995653050653985, 0.9993100882667222, 0.8802085582927391, 0.11785219190530398, 0.24252981904275153, 0.05338292212625781, 0.5575549644298038, 0.1463087495312251, 0.3295808793771769, 0.24478400514280235, 0.4092049595406092, 0.016626838085171482, 0.9962830961646875, 0.6005250554811338, 0.2026814786000639, 0.18149049770090042, 0.01538055065261868, 0.9995688656527869, 0.9965989463462549, 0.6585858175388376, 0.3080342097843048, 0.0329726759769115, 0.05947748956500147, 0.06344265553600156, 0.6750695065627667, 0.202223464521005, 0.999406915870637, 0.9982224559442671, 0.07256502561334807, 0.925204076570188, 0.9924321847040987, 0.39908721046873424, 0.26677143291386346, 0.023538655845340893, 0.3106389278983624, 0.9985667597517156, 0.2140075441216103, 0.16192378037153166, 0.4558618530204904, 0.16811195032203605, 0.9938995710911581, 0.04597408264772755, 0.9548463319143414, 0.15795140895769255, 0.3752461438797159, 0.13073379328984158, 0.33598138685068496, 0.9418039281429842, 0.05748099091952486, 0.35668403021221257, 0.270483711222474, 0.31660490993427337, 0.05598992682043766, 0.9986459379327457, 0.9997808685932749, 0.9980488908455658, 0.16845461590189964, 0.8318532063609271, 0.6617209445818982, 0.10669441940327022, 0.23171010274447576, 0.36482769161027717, 0.07282940858637996, 0.5125284548181692, 0.04968735352154894, 0.15926191207654297, 0.35140022563081563, 0.44679568565635913, 0.04257763470066631, 0.999844186967956, 0.6601263828039275, 0.1559660679985653, 0.1388098005187231, 0.04523015971958393, 0.99863342889804, 0.4990622388092247, 0.24433255441701626, 0.11473975579765656, 0.14184655894726475, 0.9940690556425983, 0.9988903905714162, 0.9990214466218957, 0.22454579154727186, 0.13492021809707322, 0.6196692874029863, 0.020238032714560983, 0.997645111631509, 0.9969193952161941, 0.9979156924181802, 0.20586582408815107, 0.7936669270766876, 0.12951364731365755, 0.8702408231777342, 0.9967611241189528, 0.9982338947142135, 0.9997668938462548, 0.4479230939738799, 0.25584393979059983, 0.11615000947548705, 0.180110994423137, 0.06915945134278327, 0.4085972182780529, 0.19740916187882582, 0.3248639361925375, 0.993861181450814, 0.7345848106731698, 0.2649804928279971, 0.159266939109544, 0.20009169248888917, 0.640595821545033, 0.15513427515540426, 0.2794808232568458, 0.20594897029301257, 0.35928978562003067, 0.9987292407198123, 0.9995820095925896, 0.9987715679081894, 0.9940878983898871, 0.9992119656816724, 0.24952763788640747, 0.24365639934790376, 0.13748483577662843, 0.36939875804752476, 0.9892454879607904, 0.5843461687448209, 0.24199247437586482, 0.17352173550207362, 0.20968162737637847, 0.7896238499300329, 0.16907724508303162, 0.0690742403692873, 0.7608476028736423, 0.9994400099019137, 0.6665360530108367, 0.3329396836221618, 0.4265948068833195, 0.2076250790782893, 0.24508042725546553, 0.12064943883994261, 0.9947389295482316, 0.9951953512141153, 0.9943420908228537, 0.5346233098344227, 0.465297022915069, 0.9902400934612022, 0.1624963329421514, 0.8372692409222716, 0.41333208450512887, 0.31765166405649153, 0.13123981042380145, 0.13765516428530014, 0.9904032777241565, 0.9974958654805682, 0.9956446099152705, 0.9713814362744183, 0.0282469561436826, 0.9967858629577038, 0.9968736131999516, 0.6106427583988683, 0.23858159407322393, 0.15064623414315167, 0.9982054457262817, 0.08651192577029264, 0.9136503380130905, 0.9949911124103222, 0.31995379113951494, 0.6792001531207247, 0.9983421152135485, 0.9957760720883895, 0.05962621996484394, 0.9407692483342044, 0.9928260547124791, 0.9987758412834642, 0.9991759085165774, 0.9983436984917531, 0.3171431894464693, 0.2833492430300422, 0.01982144934040433, 0.37985695539233877, 0.93032929507824, 0.06921487096862179, 0.2765366724383579, 0.29173945401290924, 0.18531998299104988, 0.2463235495623508, 0.3488025130560528, 0.23686588995496996, 0.40826884407850306, 0.005496887741571033, 0.9961458418394994, 0.19836457033184793, 0.31777611366032665, 0.34684339723370633, 0.13708759415012856, 0.9973663060904557, 0.992398089159338, 0.998968703412779, 0.9991814919081395, 0.9968572593625241, 0.15793346225277533, 0.7344499729574552, 0.10746600251034712, 0.998700418421644, 0.2181654238010598, 0.7171608080268881, 0.06498544538754973, 0.9995328445426436, 0.9984355884816338, 0.18097156393936617, 0.13715739582773015, 0.4946556081009342, 0.18668645543218826, 0.10410201754894471, 0.22137356743841857, 0.30321280412599255, 0.3712553878853932, 0.31364611501704626, 0.10850888322559428, 0.5781860201071812, 0.9982200754334823, 0.997669283072604, 0.9973438934113982, 0.9962841771207641, 0.05347404146808996, 0.9452830556294612, 0.9303133670084169, 0.06904669520765594, 0.9985520275376724, 0.7141243206171035, 0.28549985955416207, 0.9990538669622142, 0.9968784386643059, 0.9946227660787768, 0.9991483270024872, 0.9924316244523518, 0.05880975847010177, 0.9409561355216283, 0.995100562809744, 0.495010238377032, 0.257378366284804, 0.1700355114261745, 0.07757069902953898, 0.9974443140791383, 0.9931645878197901, 0.9993295783707832, 0.40980334855925055, 0.29354310896343405, 0.19015920409010761, 0.10655633516727325], \"Term\": [\"-\", \"-\", \"-\", \"-\", \"\\\\mathcal\", \"able\", \"able\", \"able\", \"able\", \"achieve\", \"achieve\", \"achieve\", \"adaptive\", \"adaptive\", \"admit\", \"adversarial\", \"algebra\", \"algebraic\", \"allow\", \"allow\", \"allow\", \"allow\", \"also\", \"also\", \"also\", \"also\", \"angular\", \"apply\", \"apply\", \"apply\", \"apply\", \"approximate\", \"approximate\", \"associate\", \"associate\", \"associate\", \"associate\", \"atmospheric\", \"atomic\", \"automate\", \"automatic\", \"automatically\", \"automatically\", \"autonomous\", \"available\", \"available\", \"available\", \"base\", \"base\", \"base\", \"base\", \"bayesian\", \"boolean\", \"bound\", \"bound\", \"boundary\", \"boundary\", \"bulk\", \"causal\", \"certain\", \"certain\", \"certain\", \"certain\", \"challenge\", \"challenge\", \"challenge\", \"charge\", \"class\", \"classical\", \"classical\", \"classical\", \"classical\", \"clinical\", \"collect\", \"collect\", \"commutative\", \"compact\", \"compact\", \"compact\", \"compare\", \"compare\", \"compare\", \"complete\", \"complete\", \"complete\", \"complete\", \"computational\", \"computational\", \"conditional\", \"conjecture\", \"consider\", \"consider\", \"consider\", \"consider\", \"constraint\", \"construct\", \"construct\", \"construct\", \"construct\", \"continuum\", \"convex\", \"convex\", \"convolutional\", \"cool\", \"corrupt\", \"cosmic\", \"cosmological\", \"cost\", \"couple\", \"couple\", \"critical\", \"critical\", \"critical\", \"critical\", \"dark\", \"dataset\", \"deep\", \"define\", \"define\", \"define\", \"define\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"denote\", \"deploy\", \"derive\", \"derive\", \"derive\", \"derive\", \"develop\", \"develop\", \"develop\", \"develop\", \"different\", \"different\", \"different\", \"different\", \"digital\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"distribute\", \"distribute\", \"dope\", \"due\", \"due\", \"due\", \"due\", \"efficient\", \"efficient\", \"efficient\", \"electric\", \"electromagnetic\", \"electronic\", \"elliptic\", \"empirical\", \"empirical\", \"enable\", \"enable\", \"enable\", \"enforce\", \"estimate\", \"estimate\", \"estimate\", \"euclidean\", \"evaluate\", \"evaluate\", \"evaluate\", \"exist\", \"exist\", \"exist\", \"exist\", \"explicit\", \"explicit\", \"explicit\", \"f$\", \"find\", \"find\", \"find\", \"find\", \"finite\", \"finite\", \"finite\", \"finitely\", \"first\", \"first\", \"first\", \"first\", \"fractional\", \"fractional\", \"gaussian\", \"general\", \"general\", \"general\", \"general\", \"generalize\", \"generalize\", \"generalize\", \"generate\", \"generate\", \"generate\", \"generate\", \"generative\", \"geometric\", \"geometric\", \"geometric\", \"give\", \"give\", \"give\", \"give\", \"gradient\", \"gravitational\", \"greedy\", \"guarantee\", \"help\", \"help\", \"here\", \"here\", \"here\", \"here\", \"high\", \"high\", \"high\", \"high\", \"hot\", \"however\", \"however\", \"however\", \"however\", \"human\", \"hyperbolic\", \"improve\", \"improve\", \"improve\", \"induce\", \"induce\", \"induce\", \"induce\", \"infinite\", \"integrable\", \"integral\", \"integral\", \"intractable\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"invariant\", \"investigate\", \"investigate\", \"investigate\", \"investigate\", \"irreducible\", \"iterative\", \"iterative\", \"know\", \"know\", \"know\", \"know\", \"label\", \"label\", \"large\", \"large\", \"large\", \"large\", \"latent\", \"learn\", \"let\", \"light\", \"light\", \"linear\", \"linear\", \"linear\", \"long\", \"long\", \"long\", \"long\", \"low\", \"low\", \"low\", \"low\", \"magnetic\", \"make\", \"make\", \"make\", \"make\", \"manifold\", \"many\", \"many\", \"many\", \"many\", \"marginal\", \"mass\", \"maximal\", \"measure\", \"measure\", \"measure\", \"measure\", \"mechanical\", \"medical\", \"meta\", \"metric\", \"metric\", \"minimize\", \"minimize\", \"mobile\", \"molecular\", \"neural\", \"new\", \"new\", \"new\", \"new\", \"non\", \"non\", \"non\", \"non\", \"nonparametric\", \"numerical\", \"numerical\", \"observe\", \"observe\", \"observe\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"optical\", \"optimal\", \"orbital\", \"parabolic\", \"parametric\", \"particular\", \"particular\", \"particular\", \"particular\", \"penalize\", \"perform\", \"perform\", \"perform\", \"polynomial\", \"polynomial\", \"positive\", \"positive\", \"positive\", \"posterior\", \"predict\", \"predict\", \"present\", \"present\", \"present\", \"present\", \"prime\", \"projective\", \"proof\", \"propose\", \"propose\", \"provably\", \"prove\", \"prove\", \"provide\", \"provide\", \"provide\", \"provide\", \"proximal\", \"public\", \"radial\", \"random\", \"random\", \"randomize\", \"rational\", \"real\", \"real\", \"real\", \"recurrent\", \"regular\", \"regular\", \"regularize\", \"report\", \"report\", \"riemannian\", \"robotic\", \"sample\", \"sample\", \"say\", \"scatter\", \"scientific\", \"semantic\", \"set\", \"set\", \"set\", \"set\", \"share\", \"share\", \"show\", \"show\", \"show\", \"show\", \"single\", \"single\", \"single\", \"single\", \"singular\", \"small\", \"small\", \"small\", \"small\", \"smart\", \"smoothness\", \"social\", \"solar\", \"solid\", \"solve\", \"solve\", \"solve\", \"sparse\", \"statistical\", \"statistical\", \"statistical\", \"stellar\", \"stochastic\", \"strong\", \"strong\", \"strong\", \"strong\", \"study\", \"study\", \"study\", \"study\", \"suggest\", \"suggest\", \"suggest\", \"superconducte\", \"supervise\", \"supervised\", \"surrogate\", \"symmetric\", \"symmetric\", \"temporal\", \"temporal\", \"theorem\", \"theoretical\", \"theoretical\", \"thermal\", \"thin\", \"tractable\", \"train\", \"unbiased\", \"unknown\", \"unknown\", \"unsupervised\", \"use\", \"use\", \"use\", \"use\", \"variational\", \"vertice\", \"visual\", \"well\", \"well\", \"well\", \"well\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 4, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1072412247271202404409269111\", ldavis_el1072412247271202404409269111_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1072412247271202404409269111\", ldavis_el1072412247271202404409269111_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1072412247271202404409269111\", ldavis_el1072412247271202404409269111_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "1     -0.130831 -0.068150       1        1  36.141005\n",
              "2     -0.008954 -0.106125       2        1  23.928246\n",
              "3     -0.076299  0.162541       3        1  23.219634\n",
              "0      0.216084  0.011734       4        1  16.711116, topic_info=            Term         Freq        Total Category  logprob  loglift\n",
              "45       propose  8755.000000  8755.000000  Default  30.0000  30.0000\n",
              "106        learn  4342.000000  4342.000000  Default  29.0000  29.0000\n",
              "99         prove  2904.000000  2904.000000  Default  28.0000  28.0000\n",
              "24          give  4644.000000  4644.000000  Default  27.0000  27.0000\n",
              "289      optimal  2101.000000  2101.000000  Default  26.0000  26.0000\n",
              "..           ...          ...          ...      ...      ...      ...\n",
              "91         first   765.080467  3691.265329   Topic4  -5.2146   0.2154\n",
              "421  dimensional   695.842512  2493.656678   Topic4  -5.3094   0.5127\n",
              "255      provide   751.105091  5455.661645   Topic4  -5.2330  -0.1938\n",
              "6      associate   626.460652  1365.454699   Topic4  -5.4145   1.0099\n",
              "98       present   669.750404  5553.279041   Topic4  -5.3477  -0.3261\n",
              "\n",
              "[301 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "0         1  0.248767         -\n",
              "0         2  0.329025         -\n",
              "0         3  0.235190         -\n",
              "0         4  0.186904         -\n",
              "315       4  0.995094  \\mathcal\n",
              "...     ...       ...       ...\n",
              "814       1  0.999330    visual\n",
              "119       1  0.409803      well\n",
              "119       2  0.293543      well\n",
              "119       3  0.190159      well\n",
              "119       4  0.106556      well\n",
              "\n",
              "[463 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 4, 1])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = gensimvis.prepare(lda_model, doc_term_matrix, dictionary)\n",
        "vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzgjIM3l4IXX",
        "outputId": "1300d72c-f21e-42e9-9675-c624b0644d79"
      },
      "outputs": [],
      "source": [
        "pyLDAvis.save_html(vis, 'lda_model.html')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHmTNkdA4LAx",
        "outputId": "f07fd72d-2787-4c10-cfde-d7b2d9d6801a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -7.158010503543251\n",
            "\n",
            "Coherence Score:  0.41018808458104605\n"
          ]
        }
      ],
      "source": [
        "print('\\nPerplexity: ', lda_model.log_perplexity(doc_term_matrix,total_docs=80000))\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=tokenized_reviews, dictionary=dictionary , coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(lda_model, open('model.pkl', 'wb'))\n",
        "lda_model = pickle.load(open('model.pkl', 'rb'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
